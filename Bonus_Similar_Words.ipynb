{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import tqdm\n",
    "import operator\n",
    "import datetime\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make sure the following folders have been included in the working director:\n",
    "## Best_Trained: which contains the best word embedding learned from the best logistic regression and neural net models\n",
    "## Best_Pretrained: which contains the word embedding learned of pre-trained embeddings\n",
    "## pickle: which will include the following two pickle files: 1) 10000_id2token.pkl 2) 10000_token2id.pkl\n",
    "## Fine_Tune_Weight: which will include the following files: 1) government_model.pt 2) fiction_model.pt 3) telephone_model.pt\n",
    "## 4) slate_model.pt 5) travel_model.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set up emvironment\n",
    "CURR_PATH = os.getcwd()\n",
    "WEIGHT_PATH = '/Best_Trained/'\n",
    "PRETRAINED_WEIGHT_PATH = '/Best_Pretrained/'\n",
    "FINR_WEIGHT_PATH = '/Fine_Tune_Weight/'\n",
    "VOCAB_SIZE = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for 3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load trained weight\n",
    "Best_lr = torch.load(CURR_PATH + WEIGHT_PATH + '10000_50_MUL_log-reg.pt')\n",
    "Best_nn = torch.load(CURR_PATH + WEIGHT_PATH + '10000_500_MUL_neural-net.pt')\n",
    "\n",
    "embedding_lr = Best_lr['encoder.embed.weight']\n",
    "embedding_nn = Best_nn['encoder.embed.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## laod token_index loop up tables\n",
    "id2token = pkl.load(open('pickle/'+str(VOCAB_SIZE)+'_id2token.pkl', 'rb'))\n",
    "token2id = pkl.load(open('pickle/'+str(VOCAB_SIZE)+'_token2id.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/haonantian/anaconda3/envs/nlpclass/lib/python3.6/site-packages/sklearn/utils/extmath.py:91: RuntimeWarning: invalid value encountered in sqrt\n",
      "  np.sqrt(norms, norms)\n",
      "/Users/haonantian/anaconda3/envs/nlpclass/lib/python3.6/site-packages/sklearn/utils/extmath.py:91: RuntimeWarning: invalid value encountered in sqrt\n",
      "  np.sqrt(norms, norms)\n"
     ]
    }
   ],
   "source": [
    "## Calculate similarity matrix\n",
    "simi_lr = cosine_similarity(embedding_lr)\n",
    "simi_nn = cosine_similarity(embedding_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand(simi_matrix, k=10):\n",
    "    '''\n",
    "    Expand the similarity matrix to a sorted array with similarity socres\n",
    "    '''\n",
    "    res = []\n",
    "    for i in range(len(simi_matrix)-1):\n",
    "        for j in range(i+1,len(simi_matrix[0])):\n",
    "            if simi_matrix[i][j] != 0 and simi_matrix[i][j] <= 0.99:\n",
    "                res.append(simi_matrix[i][j])\n",
    "        if i % 500 == 0:\n",
    "            print('finished {}'.format(i))\n",
    "    print('Done expanding')\n",
    "    return sorted(res)\n",
    "\n",
    "def generate_word_pair(matrix, threshold, id2_token):\n",
    "    '''\n",
    "    Generate top 10 similar tokens with the \n",
    "    '''\n",
    "    res = []\n",
    "    for i in range(len(matrix)-1):\n",
    "        for j in range(i+1, len(matrix[0])):\n",
    "            if matrix[i][j] >= threshold:\n",
    "                res.append([id2_token[i], id2_token[j]])\n",
    "        if i % 500 == 0:\n",
    "            print('finished {}'.format(i))\n",
    "    print('Done token pair generation')\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished 0\n",
      "finished 500\n",
      "finished 1000\n",
      "finished 1500\n",
      "finished 2000\n",
      "finished 2500\n",
      "finished 3000\n",
      "finished 3500\n",
      "finished 4000\n",
      "finished 4500\n",
      "finished 5000\n",
      "finished 5500\n",
      "finished 6000\n",
      "finished 6500\n",
      "finished 7000\n",
      "finished 7500\n",
      "finished 8000\n",
      "finished 8500\n",
      "finished 9000\n",
      "finished 9500\n",
      "Done expanding\n",
      "finished 0\n",
      "finished 500\n",
      "finished 1000\n",
      "finished 1500\n",
      "finished 2000\n",
      "finished 2500\n",
      "finished 3000\n",
      "finished 3500\n",
      "finished 4000\n",
      "finished 4500\n",
      "finished 5000\n",
      "finished 5500\n",
      "finished 6000\n",
      "finished 6500\n",
      "finished 7000\n",
      "finished 7500\n",
      "finished 8000\n",
      "finished 8500\n",
      "finished 9000\n",
      "finished 9500\n",
      "Done expanding\n"
     ]
    }
   ],
   "source": [
    "## Generate sorted array of similarity scores\n",
    "sorted_lr = expand(simi_lr)\n",
    "sorted_nn = expand(simi_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished 0\n",
      "finished 500\n",
      "finished 1000\n",
      "finished 1500\n",
      "finished 2000\n",
      "finished 2500\n",
      "finished 3000\n",
      "finished 3500\n",
      "finished 4000\n",
      "finished 4500\n",
      "finished 5000\n",
      "finished 5500\n",
      "finished 6000\n",
      "finished 6500\n",
      "finished 7000\n",
      "finished 7500\n",
      "finished 8000\n",
      "finished 8500\n",
      "finished 9000\n",
      "finished 9500\n",
      "Done token pair generation\n",
      "finished 0\n",
      "finished 500\n",
      "finished 1000\n",
      "finished 1500\n",
      "finished 2000\n",
      "finished 2500\n",
      "finished 3000\n",
      "finished 3500\n",
      "finished 4000\n",
      "finished 4500\n",
      "finished 5000\n",
      "finished 5500\n",
      "finished 6000\n",
      "finished 6500\n",
      "finished 7000\n",
      "finished 7500\n",
      "finished 8000\n",
      "finished 8500\n",
      "finished 9000\n",
      "finished 9500\n",
      "Done token pair generation\n"
     ]
    }
   ],
   "source": [
    "## Generate top 10 most similar token pairs\n",
    "res_lr = generate_word_pair(simi_lr, sorted_lr[-10], id2token)\n",
    "res_nn = generate_word_pair(simi_nn, sorted_nn[-10], id2token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['under', 'wakeboard'],\n",
       " ['worker', 'entertains'],\n",
       " ['Nobody', 'shower'],\n",
       " ['sad', 'joyously'],\n",
       " ['swims', 'cooler'],\n",
       " ['great', 'Island'],\n",
       " ['bars', 'sanded'],\n",
       " ['snowcapped', 'intimate'],\n",
       " ['gliding', 'beaming'],\n",
       " ['sponge', 'mountaintops']]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## top 10 similar token pairs for linear regression\n",
    "res_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['sleeping', 'Nobody'],\n",
       " ['sleeping', 'sleeps'],\n",
       " ['sleeping', 'movies'],\n",
       " ['no', 'Nobody'],\n",
       " ['lunch', 'hour'],\n",
       " ['birthday', 'joyously'],\n",
       " ['happily', 'joyously'],\n",
       " ['cats', 'sleep'],\n",
       " ['conference', 'Hispanic'],\n",
       " ['siblings', 'joyously']]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## top 10 similar token pairs for neural network\n",
    "res_nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for 3.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load pre-trained weight\n",
    "Best_pretrained = torch.load(CURR_PATH + PRETRAINED_WEIGHT_PATH + '10000_pretrained_DIRECT_neural-net.pt')\n",
    "embedding_pre = Best_pretrained['encoder.embed.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/haonantian/anaconda3/envs/nlpclass/lib/python3.6/site-packages/sklearn/utils/extmath.py:91: RuntimeWarning: invalid value encountered in sqrt\n",
      "  np.sqrt(norms, norms)\n"
     ]
    }
   ],
   "source": [
    "## Calculate similarity matrix\n",
    "pretrained_simi = cosine_similarity(embedding_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished 0\n",
      "finished 500\n",
      "finished 1000\n",
      "finished 1500\n",
      "finished 2000\n",
      "finished 2500\n",
      "finished 3000\n",
      "finished 3500\n",
      "finished 4000\n",
      "finished 4500\n",
      "finished 5000\n",
      "finished 5500\n",
      "finished 6000\n",
      "finished 6500\n",
      "finished 7000\n",
      "finished 7500\n",
      "finished 8000\n",
      "finished 8500\n",
      "finished 9000\n",
      "finished 9500\n",
      "Done expanding\n"
     ]
    }
   ],
   "source": [
    "## Generate sorted array of similarities\n",
    "sorted_pre = expand(pretrained_simi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished 0\n",
      "finished 500\n",
      "finished 1000\n",
      "finished 1500\n",
      "finished 2000\n",
      "finished 2500\n",
      "finished 3000\n",
      "finished 3500\n",
      "finished 4000\n",
      "finished 4500\n",
      "finished 5000\n",
      "finished 5500\n",
      "finished 6000\n",
      "finished 6500\n",
      "finished 7000\n",
      "finished 7500\n",
      "finished 8000\n",
      "finished 8500\n",
      "finished 9000\n",
      "finished 9500\n",
      "Done token pair generation\n"
     ]
    }
   ],
   "source": [
    "## Generate top 10 similar token pairs for pre-trained embedding\n",
    "res_pretrained = generate_word_pair(pretrained_simi, sorted_pre[-10], id2token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['13', '14'],\n",
       " ['14', '15'],\n",
       " ['14', '16'],\n",
       " ['14', '19'],\n",
       " ['19', '23'],\n",
       " ['19', '21'],\n",
       " ['22', '23'],\n",
       " ['22', '21'],\n",
       " ['53', '56'],\n",
       " ['23', '21']]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Present the result for pretrained embedding\n",
    "res_pretrained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for 3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load fine tuned embedding\n",
    "gov_embedding = torch.load(CURR_PATH + FINR_WEIGHT_PATH + 'government_model.pt')\n",
    "fic_embedding = torch.load(CURR_PATH + FINR_WEIGHT_PATH + 'fiction_model.pt')\n",
    "slate_embedding = torch.load(CURR_PATH + FINR_WEIGHT_PATH + 'slate_model.pt')\n",
    "tele_embedding = torch.load(CURR_PATH + FINR_WEIGHT_PATH + 'telephone_model.pt')\n",
    "tra_embedding = torch.load(CURR_PATH + FINR_WEIGHT_PATH + 'travel_model.pt')\n",
    "\n",
    "gov_embedding = gov_embedding['encoder.embed.weight'].numpy().tolist()\n",
    "fic_embedding = fic_embedding['encoder.embed.weight'].numpy().tolist()\n",
    "slate_embedding = slate_embedding['encoder.embed.weight'].numpy().tolist()\n",
    "tele_embedding = tele_embedding['encoder.embed.weight'].numpy().tolist()\n",
    "tra_embedding = tra_embedding['encoder.embed.weight'].numpy().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_simi(vec1, vec2):\n",
    "    return np.dot(vec1, vec2) / (np.sqrt(np.dot(vec1, vec1)) * np.sqrt(np.dot(vec2, vec2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "## calculate similarity matrix\n",
    "def calculate_simi(arr1, arr2):\n",
    "    res = {}\n",
    "    for i in range(len(arr1)):\n",
    "        res[i] = cosine_simi(arr1[i], arr2[i])\n",
    "    return res\n",
    "\n",
    "def top_ten_change(simi, id2token, k=12):\n",
    "    res = {}\n",
    "    for i in range(len(simi)):\n",
    "        res[i] = simi[i]\n",
    "    sorted_res = sorted(res.items(), key=lambda kv: kv[1])\n",
    "    result = []\n",
    "    counter = 0\n",
    "    for key in sorted_res:\n",
    "        if counter < k:\n",
    "            result.append(id2token[key[0]])\n",
    "            counter += 1\n",
    "        else:\n",
    "            break\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/haonantian/anaconda3/envs/nlpclass/lib/python3.6/site-packages/ipykernel_launcher.py:2: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "gov_simi = calculate_simi(gov_embedding, embedding_nn)\n",
    "fic_simi = calculate_simi(fic_embedding, embedding_nn)\n",
    "slate_simi = calculate_simi(slate_embedding, embedding_nn)\n",
    "tele_simi = calculate_simi(tele_embedding, embedding_nn)\n",
    "tra_simi = calculate_simi(tra_embedding, embedding_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<pad>',\n",
       " 'required',\n",
       " 'ignored',\n",
       " 'executive',\n",
       " 'success',\n",
       " 'deal',\n",
       " 'senior',\n",
       " 'provides',\n",
       " 'just',\n",
       " 'did',\n",
       " 'largest',\n",
       " 'same']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Top change for gov\n",
    "top_ten_change(gov_simi, id2token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<pad>',\n",
       " 'people',\n",
       " 'mist',\n",
       " 'hit',\n",
       " 'paid',\n",
       " 'contents',\n",
       " 'reach',\n",
       " 'during',\n",
       " 'general',\n",
       " 'changing',\n",
       " 'hearing',\n",
       " 'many']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Top change for fic\n",
    "top_ten_change(fic_simi, id2token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<pad>',\n",
       " 'full',\n",
       " 'operation',\n",
       " 'image',\n",
       " 'trying',\n",
       " 'era',\n",
       " 'seemingly',\n",
       " 'dreams',\n",
       " 'determine',\n",
       " 'players',\n",
       " '%',\n",
       " 'garden']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Top change for slate\n",
    "top_ten_change(slate_simi, id2token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<pad>',\n",
       " 'peace',\n",
       " 'aim',\n",
       " 'expert',\n",
       " 'hated',\n",
       " 'got',\n",
       " 'price',\n",
       " 'never',\n",
       " 'meet',\n",
       " 'Donald',\n",
       " 'entire',\n",
       " 'hand']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_ten_change(tele_simi, id2token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<pad>',\n",
       " 'nothing',\n",
       " 'never',\n",
       " 'most',\n",
       " 'tourists',\n",
       " 'their',\n",
       " 'wo',\n",
       " 'Many',\n",
       " 'any',\n",
       " 'anywhere',\n",
       " 'houses',\n",
       " 'make']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_ten_change(tra_simi, id2token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader\n",
    "Please be sure that this directory is cloned under the directory for HW1. The structure of HW1 folder should be as followed.\n",
    "- HW1\n",
    "    - data\n",
    "        - mnli_train.tsv\n",
    "        - mnli_val.tsv\n",
    "        - snli_train.tsv\n",
    "        - snli_val.tsv\n",
    "    - < name of this github repo >\n",
    "        - < the current notebook >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import datetime\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../data/'\n",
    "VEC_PATH = '../wiki-news-300d-1M.vec'\n",
    "\n",
    "VOCAB_SIZE = 50000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "snli_train = pd.read_csv(DATA_PATH + \"snli_train.tsv\", sep='\\t')\n",
    "snli_val = pd.read_csv(DATA_PATH + \"snli_val.tsv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Make directory /pickle/ if it doesn't already exist.\n",
    "# import os\n",
    "# os.mkdir(os.getcwd()+'/pickle/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The current `50000_vectors.pkl`, `50000_id2token.pkl`, and `50000_token2id.pkl` is for `vocab size` of `50000`. The files can be downloaded from https://drive.google.com/open?id=1Fn49uTsw03KHZ6VsoG-eYwaPRYAwnqPe and should be saved under `os.getcwd()+'/pickle/'`. Need to re-run the block of code below for other `vocab size` options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(datetime.datetime.now().strftime(\"%H:%M:%S\"))\n",
    "# train_data = load_data.prepare_data(snli_train)\n",
    "# token2id, id2token, vectors = load_data.build_vocabulary(train_data, VEC_PATH, VOCAB_SIZE)\n",
    "# pkl.dump(vectors, open('pickle/'+str(VOCAB_SIZE)+'_vectors.pkl', 'wb'))\n",
    "# pkl.dump(token2id, open('pickle/'+str(VOCAB_SIZE)+'_token2id.pkl', 'wb'))\n",
    "# pkl.dump(id2token, open('pickle/'+str(VOCAB_SIZE)+'_id2token.pkl', 'wb'))\n",
    "# print(datetime.datetime.now().strftime(\"%H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = load_data.prepare_data(snli_train)\n",
    "val_data = load_data.prepare_data(snli_val)\n",
    "vectors = pkl.load(open('pickle/'+str(VOCAB_SIZE)+'_vectors.pkl', 'rb'))\n",
    "id2token = pkl.load(open('pickle/'+str(VOCAB_SIZE)+'_id2token.pkl', 'rb'))\n",
    "token2id = pkl.load(open('pickle/'+str(VOCAB_SIZE)+'_token2id.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size is 100000\n",
      "Val dataset size is 1000\n",
      "Total number of vocab built from train dataset is 22059\n"
     ]
    }
   ],
   "source": [
    "# double checking\n",
    "print (\"Train dataset size is {}\".format(len(train_data)))\n",
    "print (\"Val dataset size is {}\".format(len(val_data)))\n",
    "print (\"Total number of vocab built from train dataset is {}\".format(len(set(id2token))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token id 85 ; token some\n",
      "Token some; token id 85\n"
     ]
    }
   ],
   "source": [
    "# Lets check the dictionary by loading random token from it\n",
    "random_token_id = random.randint(0, len(id2token)-1)\n",
    "random_token = id2token[random_token_id]\n",
    "\n",
    "print (\"Token id {} ; token {}\".format(random_token_id, id2token[random_token_id]))\n",
    "print (\"Token {}; token id {}\".format(random_token, token2id[random_token]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## token2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>[A, young, girl, in, a, pink, shirt, sitting, ...</td>\n",
       "      <td>[A, young, girl, watching, the, sunset, over, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>[A, woman, is, smiling, while, the, man, next,...</td>\n",
       "      <td>[Two, people, are, next, to, each, other, .]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>[Across, the, river, ,, you, can, see, a, larg...</td>\n",
       "      <td>[The, large, building, is, full, of, apartment...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>[a, man, in, white, shorts, and, a, black, shi...</td>\n",
       "      <td>[A, man, is, riding, a, jetski, on, the, ocean...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>[Four, black, dogs, run, together, on, bright,...</td>\n",
       "      <td>[Four, dogs, are, preparing, to, be, launched,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentence1  \\\n",
       "0  [A, young, girl, in, a, pink, shirt, sitting, ...   \n",
       "1  [A, woman, is, smiling, while, the, man, next,...   \n",
       "2  [Across, the, river, ,, you, can, see, a, larg...   \n",
       "3  [a, man, in, white, shorts, and, a, black, shi...   \n",
       "4  [Four, black, dogs, run, together, on, bright,...   \n",
       "\n",
       "                                           sentence2  label  \n",
       "0  [A, young, girl, watching, the, sunset, over, ...      1  \n",
       "1       [Two, people, are, next, to, each, other, .]      2  \n",
       "2  [The, large, building, is, full, of, apartment...      1  \n",
       "3  [A, man, is, riding, a, jetski, on, the, ocean...      0  \n",
       "4  [Four, dogs, are, preparing, to, be, launched,...      0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot sentence length to determine a good value for MAX_SENTENCE_LENGTH\n",
    "train_data.sentence1.str.len().plot(kind='hist', legend=True);\n",
    "train_data.sentence2.str.len().plot(kind='hist', legend=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determined `MAX_SENTENCE_LENGTH = 30`. This variable is specified in load_data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "indiced_train_data, train_target = load_data.token2index_dataset(train_data, token2id)\n",
    "indiced_val_data, val_target = load_data.token2index_dataset(val_data, token2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 24, 25, 5, 3, 106, 26, 33, 9, 3, 736, 1972, 3, 361, 12, 52, 2]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# double checking- an example of the indiced data\n",
    "indiced_train_data['sentence1'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# double checking- target value\n",
    "train_target[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "train_dataset = load_data.SNLIDataset(indiced_train_data, train_target)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=load_data.SNLI_collate_func,\n",
    "                                           shuffle=True)\n",
    "\n",
    "val_dataset = load_data.SNLIDataset(indiced_val_data, val_target)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_dataset, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=load_data.SNLI_collate_func,\n",
    "                                           shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 6, 20, 23, 13, 10, 19, 10, 11,  8, 16, 29, 15, 27, 10, 28, 11,  8, 30,\n",
      "         8, 22,  6, 10, 20, 13, 10, 17, 30, 19, 12, 22,  8,  9]) torch.Size([32, 30])\n",
      "tensor([ 8,  9, 14, 17,  4,  8,  5,  9, 13,  7,  9,  7,  9,  3,  5,  8,  4, 26,\n",
      "         3,  7,  6,  5, 10,  9, 14,  8, 11,  7,  8,  9,  7,  9]) torch.Size([32, 30])\n",
      "tensor([2, 0, 1, 1, 2, 0, 2, 1, 0, 2, 2, 1, 0, 2, 2, 1, 2, 1, 0, 0, 0, 0, 1, 0,\n",
      "        1, 0, 2, 1, 2, 1, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "# check that the dataloader works\n",
    "for i, (x1, x1_lengths, x2, x2_lengths, labels) in enumerate(train_loader):\n",
    "    print(x1_lengths, x1.size())\n",
    "    print(x2_lengths, x2.size())\n",
    "    print(labels)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([22059, 300])\n"
     ]
    }
   ],
   "source": [
    "# create weights matrix from pretrained vectors\n",
    "weights_matrix = load_data.create_weights(vectors, id2token)\n",
    "print(weights_matrix.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "how to use the pretrained embedding in model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding(22059, 300)\n",
      "torch.Size([32, 30, 300])\n"
     ]
    }
   ],
   "source": [
    "emb_layer, num_embeddings, embedding_dim = load_data.create_emb_layer(weights_matrix)\n",
    "\n",
    "print(emb_layer)\n",
    "\n",
    "for x1, x1_lengths, x2, x2_lengths, labels in train_loader:\n",
    "    print(emb_layer(x1).size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "embedding size = (batch size * max sentence length * embedding dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
